{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab5-2.ipynb","version":"0.3.2","provenance":[{"file_id":"13M6-v79L7kscS-KpEgaJvAjZR7qzz7jh","timestamp":1562654440166}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KDb6bdje7J8Q","colab_type":"text"},"source":["# X-Ray Image Classification Demo"]},{"cell_type":"markdown","metadata":{"id":"8cT-gWs57oy5","colab_type":"text"},"source":["## 1. Download data and preparation"]},{"cell_type":"markdown","metadata":{"id":"kc8TAQSO_1wl","colab_type":"text"},"source":["1.1 Clone the image files from Github"]},{"cell_type":"code","metadata":{"id":"rezBfiyo7OIz","colab_type":"code","colab":{}},"source":["! git clone https://github.com/jsphchan/ChestX-ray8.git"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0VYb7D4i_9Ln","colab_type":"text"},"source":["1.2 List the X-Ray image files that belong to the class \"No Finding\"."]},{"cell_type":"code","metadata":{"id":"PSiw8KdLBxew","colab_type":"code","colab":{}},"source":["! ls ChestX-ray8/images/test/0_nofinding"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TrOf3NggAHn6","colab_type":"text"},"source":["1.3 List the X-Ray image files that belong to the class \"Effusion\"."]},{"cell_type":"code","metadata":{"id":"BJTUo-yYGChg","colab_type":"code","colab":{}},"source":["! ls ChestX-ray8/images/test/1_effusion"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AEat9Pox7OpD","colab_type":"text"},"source":["## 2. Train model using VGG16 model and test the accuracy\n","\n"]},{"cell_type":"code","metadata":{"id":"JKEqCC_G7QUz","colab_type":"code","colab":{}},"source":["import numpy as np\n","from tensorflow import keras\n","\n","hyperparameter_epoch = 5\n","hyperparameter_minibatch = 16\n","hyperparameter_lr = 0.0001\n","\n","train_datagen = keras.preprocessing.image.ImageDataGenerator(\n","        horizontal_flip=True,\n","        width_shift_range=0.15,\n","        height_shift_range=0.15,\n","        rotation_range=5,\n","        shear_range=0.01,\n","        zoom_range=0.10)\n","train_generator = train_datagen.flow_from_directory(\n","        'ChestX-ray8/images/train',\n","        batch_size=hyperparameter_minibatch,\n","        target_size=(224, 224),\n","        class_mode='binary')\n","\n","val_datagen = keras.preprocessing.image.ImageDataGenerator()\n","val_generator = val_datagen.flow_from_directory(\n","        r'ChestX-ray8/images/val',\n","        batch_size=hyperparameter_minibatch,\n","        target_size=(224, 224),\n","        class_mode='binary',\n","        shuffle=False)\n","\n","test_datagen = keras.preprocessing.image.ImageDataGenerator()\n","test_generator = test_datagen.flow_from_directory(\n","        'ChestX-ray8/images/test',\n","        batch_size=hyperparameter_minibatch,\n","        target_size=(224, 224),\n","        class_mode='binary',\n","        shuffle=False)\n","\n","model_vgg16 = keras.applications.vgg16.VGG16(\n","        include_top=False,\n","        weights='imagenet',\n","        input_shape=(224, 224, 3))\n","\n","for layer in model_vgg16.layers[0:len(model_vgg16.layers)*9//10]:  \n","    layer.trainable = False\n","\n","y = model_vgg16.output\n","y = keras.layers.GlobalAveragePooling2D()(y)\n","y = keras.layers.Dense(1, activation='sigmoid')(y)\n","model = keras.models.Model(model_vgg16.input, y)\n","model.summary()\n","\n","adam = keras.optimizers.Adam(lr=hyperparameter_lr)\n","model.compile(\n","        optimizer=adam,\n","        loss=keras.losses.binary_crossentropy,\n","        metrics=['accuracy'])\n","\n","train_step = train_generator.samples // hyperparameter_minibatch\n","val_step = val_generator.samples // hyperparameter_minibatch\n","test_step = test_generator.samples // hyperparameter_minibatch\n","\n","model.fit_generator(generator=train_generator,\n","        steps_per_epoch=train_step,\n","        epochs=hyperparameter_epoch,\n","        validation_data=val_generator,\n","        validation_steps=val_step,\n","        verbose=1)\n","\n","y_prob = model.predict_generator(generator=test_generator,\n","        steps=test_step)\n","y_pred = np.where(y_prob >= 0.5, 1, 0)\n","y_true = test_generator.classes.reshape(y_pred.shape)\n","\n","print('Test Accuracy = %.4f' % np.mean(y_pred == y_true))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2d7g0bqi-ekf","colab_type":"text"},"source":["## 3. Try using the trained model to classify X-Ray image files"]},{"cell_type":"markdown","metadata":{"id":"xsjmzLlYAb4w","colab_type":"text"},"source":["3.1 Test a sample X-Ray image file from \"No Findings\" class"]},{"cell_type":"code","metadata":{"id":"m64Epbe8-ss7","colab_type":"code","colab":{}},"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","image0 = cv2.imread('ChestX-ray8/images/test/0_nofinding/00000539_000.png')\n","image0_resize = cv2.resize(image0, (224, 224))\n","image0_batch = image0_resize[np.newaxis, ...]\n","print('Probability of Effusion   = %.4f' % np.squeeze(model.predict(image0_batch)))\n","print('Probability of No Finding = %.4f' % (1 - np.squeeze(model.predict(image0_batch))))\n","cv2_imshow(image0_resize)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LiSefurxAjeQ","colab_type":"text"},"source":["3.2 Test a sample X-Ray image file from \"Effusion\" class"]},{"cell_type":"code","metadata":{"id":"l_jDAAVIDjQj","colab_type":"code","colab":{}},"source":["image1 = cv2.imread('ChestX-ray8/images/test/1_effusion/00022670_000.png')\n","image1_resize = cv2.resize(image1, (224, 224))\n","image1_batch = image1_resize[np.newaxis, ...]\n","print('Probability of Effusion   = %.4f' % np.squeeze(model.predict(image1_batch)))\n","print('Probability of No Finding = %.4f' % (1 - np.squeeze(model.predict(image1_batch))))\n","cv2_imshow(image1_resize)"],"execution_count":0,"outputs":[]}]}